{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9f91b0",
   "metadata": {},
   "source": [
    "# Deep Dive: Time Series Cross-Validation Implementation\n",
    "## Complete Line-by-Line Analysis with Theory, Logic, and Interconnected Reasoning\n",
    "\n",
    "### Overview\n",
    "This notebook provides a comprehensive, deeply reasoned explanation of our improved time series cross-validation implementation. We'll examine every design choice, understand the theoretical foundations, and see how each decision connects to previous ones in a logical chain of reasoning.\n",
    "\n",
    "### What We'll Cover:\n",
    "1. **Theoretical Foundation**: Why traditional CV fails for time series\n",
    "2. **Import Strategy**: Each library choice and its purpose\n",
    "3. **Data Structures**: Every field, type hint, and their interconnections\n",
    "4. **Class Architecture**: Design patterns and their justifications\n",
    "5. **Split Generation Logic**: Mathematical foundation and implementation\n",
    "6. **Boundary Calculations**: Precise temporal alignment reasoning\n",
    "7. **Index Extraction**: Memory efficiency and accuracy trade-offs\n",
    "8. **Model Training Pipeline**: Isolation principles and validation\n",
    "9. **Loss Calculation**: Per-origin tracking and aggregation strategies\n",
    "10. **Statistical Testing**: Preparation for rigorous model comparison\n",
    "\n",
    "### Learning Philosophy\n",
    "- **Every choice has a reason** - we'll explain the \"why\" behind each decision\n",
    "- **Connections matter** - we'll show how each step builds on previous ones\n",
    "- **Context is key** - we'll relate everything to practical time series forecasting\n",
    "- **No shortcuts** - we'll dive deep into the mathematical and logical foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2385773",
   "metadata": {},
   "source": [
    "## 1. Theoretical Foundation: Why Traditional Cross-Validation Fails\n",
    "\n",
    "### The Core Problem\n",
    "Traditional k-fold cross-validation assumes **exchangeable data** - that any subset can represent the population. This assumption is **fundamentally violated** in time series because:\n",
    "\n",
    "1. **Temporal Dependencies**: Future values depend on past values\n",
    "2. **Data Leakage**: Using future data to predict the past creates unrealistic performance estimates\n",
    "3. **Non-Stationarity**: Statistical properties change over time\n",
    "4. **Seasonality**: Patterns repeat at regular intervals\n",
    "\n",
    "### What We Need Instead\n",
    "For time series, we need **time-aware validation** that:\n",
    "- Respects temporal order (never train on future to predict past)\n",
    "- Maintains realistic forecasting scenarios\n",
    "- Tracks performance across different time periods\n",
    "- Enables statistical comparison between models\n",
    "\n",
    "### Our Solution: Rolling Origin Cross-Validation\n",
    "We implement a variant that:\n",
    "1. **Preserves temporal order**: Training always precedes testing\n",
    "2. **Creates realistic scenarios**: Each fold simulates real forecasting\n",
    "3. **Tracks per-origin performance**: Enables detailed analysis\n",
    "4. **Supports statistical testing**: Provides data for model comparison\n",
    "\n",
    "This foundation drives every design choice we'll examine next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864385f",
   "metadata": {},
   "source": [
    "## 2. Import Strategy: Every Library Choice Has a Purpose\n",
    "\n",
    "Let's examine each import and understand why it's essential for our implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ef7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Analysis:\n",
      "================\n",
      "numpy (as np): Mathematical operations, array handling\n",
      "  - Why: Fast numerical computation for index calculations\n",
      "  - Connection: Foundation for efficient data manipulation\n",
      "\n",
      "pandas (as pd): Data structure and time series handling\n",
      "  - Why: DatetimeIndex operations, data alignment\n",
      "  - Connection: Builds on numpy for structured time series data\n",
      "\n",
      "torch: Deep learning framework\n",
      "  - Why: Model training, loss computation, device management\n",
      "  - Connection: Our models are PyTorch-based, needs tensor operations\n",
      "\n",
      "dataclasses: Structured data containers\n",
      "  - Why: Type-safe, self-documenting data structures\n",
      "  - Connection: Replaces error-prone dictionaries with validated objects\n",
      "\n",
      "typing: Type hints and annotations\n",
      "  - Why: Code clarity, IDE support, runtime validation\n",
      "  - Connection: Essential for maintainable, large-scale projects\n",
      "\n",
      "defaultdict: Automatic dictionary initialization\n",
      "  - Why: Simplifies nested data structure creation\n",
      "  - Connection: Reduces boilerplate in loss aggregation\n"
     ]
    }
   ],
   "source": [
    "# Let's examine our imports and understand each choice\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Dict, Optional, Any, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Import Analysis:\")\n",
    "print(\"================\")\n",
    "print(\"numpy (as np): Mathematical operations, array handling\")\n",
    "print(\"  - Why: Fast numerical computation for index calculations\")\n",
    "print(\"  - Connection: Foundation for efficient data manipulation\")\n",
    "print()\n",
    "print(\"pandas (as pd): Data structure and time series handling\")\n",
    "print(\"  - Why: DatetimeIndex operations, data alignment\")\n",
    "print(\"  - Connection: Builds on numpy for structured time series data\")\n",
    "print()\n",
    "print(\"torch: Deep learning framework\")\n",
    "print(\"  - Why: Model training, loss computation, device management\")\n",
    "print(\"  - Connection: Our models are PyTorch-based, needs tensor operations\")\n",
    "print()\n",
    "print(\"dataclasses: Structured data containers\")\n",
    "print(\"  - Why: Type-safe, self-documenting data structures\")\n",
    "print(\"  - Connection: Replaces error-prone dictionaries with validated objects\")\n",
    "print()\n",
    "print(\"typing: Type hints and annotations\")\n",
    "print(\"  - Why: Code clarity, IDE support, runtime validation\")\n",
    "print(\"  - Connection: Essential for maintainable, large-scale projects\")\n",
    "print()\n",
    "print(\"defaultdict: Automatic dictionary initialization\")\n",
    "print(\"  - Why: Simplifies nested data structure creation\")\n",
    "print(\"  - Connection: Reduces boilerplate in loss aggregation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b863a8",
   "metadata": {},
   "source": [
    "## 3. Data Structures: The Foundation of Type Safety and Clarity\n",
    "\n",
    "Our implementation uses three key dataclasses. Let's understand why each field exists and how they interconnect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff05b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structure 1: CVFold - Represents a single cross-validation fold\n",
    "@dataclass\n",
    "class CVFold:\n",
    "    \"\"\"\n",
    "    A single cross-validation fold with complete information about train/test splits.\n",
    "    \n",
    "    WHY THIS STRUCTURE:\n",
    "    - Encapsulates all information needed for one fold\n",
    "    - Type safety prevents common indexing errors\n",
    "    - Self-documenting through field names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Core split information - the fundamental data\n",
    "    train_indices: np.ndarray  # WHERE to train (indices into original data)\n",
    "    test_indices: np.ndarray   # WHERE to test (indices into original data)\n",
    "    \n",
    "    # Temporal context - connects this fold to the time dimension\n",
    "    origin_date: pd.Timestamp  # WHEN this fold's forecast originates\n",
    "    test_start_date: pd.Timestamp  # WHEN the test period begins\n",
    "    test_end_date: pd.Timestamp    # WHEN the test period ends\n",
    "    \n",
    "    # Metadata - helps with debugging and analysis\n",
    "    fold_number: int           # WHICH fold this is (for ordering/tracking)\n",
    "\n",
    "print(\"CVFold Design Rationale:\")\n",
    "print(\"========================\")\n",
    "print(\"✓ train_indices: np.ndarray - Fast integer indexing, memory efficient\")\n",
    "print(\"✓ test_indices: np.ndarray - Consistent with train_indices type\")\n",
    "print(\"✓ origin_date: pd.Timestamp - Precise temporal reference point\")\n",
    "print(\"✓ test_start/end_date: pd.Timestamp - Define exact test window\")\n",
    "print(\"✓ fold_number: int - Simple ordering for analysis\")\n",
    "print()\n",
    "print(\"KEY INSIGHT: Each fold is completely self-contained\")\n",
    "print(\"- No dependencies on external state\")\n",
    "print(\"- Can be processed independently\")\n",
    "print(\"- Contains all information needed for reproducible training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structure 2: CVResults - Comprehensive results from cross-validation\n",
    "@dataclass\n",
    "class CVResults:\n",
    "    \"\"\"\n",
    "    Complete results from cross-validation with multi-level loss tracking.\n",
    "    \n",
    "    WHY THIS HIERARCHICAL STRUCTURE:\n",
    "    - Different analysis levels need different aggregations\n",
    "    - Statistical testing requires per-origin data\n",
    "    - Debugging needs fold-level detail\n",
    "    \"\"\"\n",
    "    \n",
    "    # Per-origin losses - the finest granularity\n",
    "    per_origin_losses: Dict[str, List[float]] = field(default_factory=dict)\n",
    "    # Structure: {origin_date_str: [loss_step1, loss_step2, ...]}\n",
    "    # WHY: Enables per-timepoint analysis and statistical testing\n",
    "    \n",
    "    # Per-fold losses - intermediate aggregation\n",
    "    per_fold_losses: Dict[str, float] = field(default_factory=dict) \n",
    "    # Structure: {fold_identifier: average_loss_for_fold}\n",
    "    # WHY: Fold-level performance comparison and debugging\n",
    "    \n",
    "    # Overall metrics - highest level aggregation  \n",
    "    overall_metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    # Structure: {metric_name: aggregated_value}\n",
    "    # WHY: Single numbers for model comparison and reporting\n",
    "\n",
    "print(\"CVResults Design Rationale:\")\n",
    "print(\"===========================\")\n",
    "print(\"✓ Three-tier structure matches analysis needs:\")\n",
    "print(\"  - per_origin_losses: Statistical testing, temporal analysis\")\n",
    "print(\"  - per_fold_losses: Cross-validation diagnostics\")  \n",
    "print(\"  - overall_metrics: Model comparison, reporting\")\n",
    "print()\n",
    "print(\"✓ Dict with default_factory prevents KeyError issues\")\n",
    "print(\"✓ String keys enable flexible metric naming\")\n",
    "print(\"✓ Hierarchical design allows drilling down from summary to detail\")\n",
    "print()\n",
    "print(\"CRITICAL CONNECTION: This structure directly supports\")\n",
    "print(\"the Diebold-Mariano test for statistical significance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e443f0",
   "metadata": {},
   "source": [
    "## 4. Class Architecture: The ImprovedTimeSeriesCrossValidator\n",
    "\n",
    "Now we examine the main class. Every design choice here builds on our previous decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Definition and Initialization\n",
    "class ImprovedTimeSeriesCrossValidator:\n",
    "    \"\"\"\n",
    "    Time series cross-validator with proper temporal splits and comprehensive tracking.\n",
    "    \n",
    "    DESIGN PHILOSOPHY:\n",
    "    - Explicit is better than implicit (all parameters are clear)\n",
    "    - Fail fast (validation in __init__)\n",
    "    - Single responsibility (this class only does CV splitting and tracking)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_splits: int = 5,\n",
    "                 train_size: Optional[int] = None,\n",
    "                 test_size: int = 1,\n",
    "                 gap: int = 0,\n",
    "                 expanding_window: bool = True):\n",
    "        \"\"\"\n",
    "        WHY EACH PARAMETER EXISTS:\n",
    "        \n",
    "        n_splits: int = 5\n",
    "        - DEFAULT RATIONALE: 5 is the most common CV choice, balances bias/variance\n",
    "        - CONNECTION: More splits = less bias but more variance in performance estimates\n",
    "        - PRACTICAL: With daily data, 5 splits gives good temporal coverage\n",
    "        \n",
    "        train_size: Optional[int] = None  \n",
    "        - DEFAULT RATIONALE: None means use all available data (expanding window)\n",
    "        - CONNECTION: Fixed size creates walk-forward window, None creates expanding\n",
    "        - TRADE-OFF: Fixed size = consistent train data volume, expanding = more data\n",
    "        \n",
    "        test_size: int = 1\n",
    "        - DEFAULT RATIONALE: Single-step ahead is most common forecasting scenario\n",
    "        - CONNECTION: Matches our per-origin loss tracking (1 prediction per origin)\n",
    "        - FLEXIBILITY: Can increase for multi-step forecasting\n",
    "        \n",
    "        gap: int = 0\n",
    "        - DEFAULT RATIONALE: No gap assumes immediate forecasting capability\n",
    "        - CONNECTION: Real-world may need gaps for data availability delays\n",
    "        - SAFETY: Prevents accidental data leakage if processing delays exist\n",
    "        \n",
    "        expanding_window: bool = True\n",
    "        - DEFAULT RATIONALE: More training data generally improves performance\n",
    "        - CONNECTION: If train_size is None, this parameter is ignored\n",
    "        - CHOICE: expanding=True uses all past data, False uses fixed window\n",
    "        \"\"\"\n",
    "        \n",
    "        # VALIDATION LOGIC: Fail fast with clear error messages\n",
    "        if n_splits < 2:\n",
    "            raise ValueError(\"n_splits must be at least 2 for meaningful cross-validation\")\n",
    "        if test_size < 1:\n",
    "            raise ValueError(\"test_size must be at least 1\")\n",
    "        if gap < 0:\n",
    "            raise ValueError(\"gap cannot be negative\")\n",
    "            \n",
    "        # Store parameters for later use\n",
    "        self.n_splits = n_splits\n",
    "        self.train_size = train_size  \n",
    "        self.test_size = test_size\n",
    "        self.gap = gap\n",
    "        self.expanding_window = expanding_window\n",
    "\n",
    "print(\"Class Initialization Design Rationale:\")\n",
    "print(\"======================================\")\n",
    "print(\"✓ All parameters have sensible defaults based on common use cases\")\n",
    "print(\"✓ Validation prevents silent failures later in the pipeline\")  \n",
    "print(\"✓ Parameter storage enables method access without globals\")\n",
    "print(\"✓ Type hints make usage clear and enable IDE support\")\n",
    "print()\n",
    "print(\"KEY INSIGHT: This initialization establishes the 'contract'\")\n",
    "print(\"for what kind of cross-validation we'll perform.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c424662",
   "metadata": {},
   "source": [
    "## 5. Split Generation Logic: The Heart of Time Series Cross-Validation\n",
    "\n",
    "The `get_rolling_origin_aligned_splits` method is where theory meets practice. Let's understand every line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_origin_aligned_splits(self, data: pd.DataFrame) -> List[CVFold]:\n",
    "    \"\"\"\n",
    "    Generate time series cross-validation splits aligned with RollingOrigin evaluation.\n",
    "    \n",
    "    MATHEMATICAL FOUNDATION:\n",
    "    For time series with T observations, we need splits that:\n",
    "    1. Preserve temporal order: train_end < test_start\n",
    "    2. Have consistent test window size\n",
    "    3. Align with forecast origins for proper evaluation\n",
    "    \n",
    "    WHY \"ROLLING ORIGIN ALIGNED\":\n",
    "    - Rolling: Each fold advances the origin point forward in time\n",
    "    - Origin: The point in time from which we make forecasts  \n",
    "    - Aligned: Test periods align with evaluation framework\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Input validation - fail fast with clear messages\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Data must have DatetimeIndex for time series CV\")\n",
    "    # WHY: We need temporal information for proper splitting\n",
    "    # CONNECTION: This validates our assumption from theoretical foundation\n",
    "    \n",
    "    if len(data) < self.n_splits + self.test_size + self.gap:\n",
    "        raise ValueError(f\"Data too short: need at least {self.n_splits + self.test_size + self.gap} points\")\n",
    "    # WHY: Ensures we can create the requested number of splits\n",
    "    # MATH: n_splits origins + test_size per split + gap between train/test\n",
    "    # CONNECTION: Builds on our initialization parameter validation\n",
    "    \n",
    "    print(\"Step 1 Analysis:\")\n",
    "    print(\"===============\")\n",
    "    print(\"✓ DatetimeIndex validation ensures we can work with temporal data\")\n",
    "    print(\"✓ Length validation prevents impossible split requests\")  \n",
    "    print(\"✓ Both connect back to our theoretical foundation of time-aware CV\")\n",
    "    \n",
    "    # STEP 2: Calculate fold boundaries - the core mathematical logic\n",
    "    fold_boundaries = self._calculate_fold_boundaries(len(data))\n",
    "    # WHY: Separates complex boundary logic into testable function\n",
    "    # CONNECTION: This is where our n_splits parameter gets translated to actual indices\n",
    "    \n",
    "    print(\"\\nStep 2 Analysis:\")\n",
    "    print(\"===============\")\n",
    "    print(\"✓ Fold boundaries define WHERE each split occurs in time\")\n",
    "    print(\"✓ Separation of concerns: this method orchestrates, _calculate_fold_boundaries computes\")\n",
    "    print(\"✓ Mathematical logic isolated for testing and validation\")\n",
    "    \n",
    "    # STEP 3: Generate actual indices for each fold\n",
    "    folds = []\n",
    "    for i, (train_start, train_end, test_start, test_end) in enumerate(fold_boundaries):\n",
    "        # Extract indices using our boundary calculations\n",
    "        train_indices, test_indices = self._generate_aligned_indices(\n",
    "            data, train_start, train_end, test_start, test_end\n",
    "        )\n",
    "        # WHY: Another separation of concerns - boundaries vs actual index extraction\n",
    "        # CONNECTION: Uses our CVFold structure to encapsulate results\n",
    "        \n",
    "        # Create fold with complete temporal context\n",
    "        fold = CVFold(\n",
    "            train_indices=train_indices,\n",
    "            test_indices=test_indices,\n",
    "            origin_date=data.index[test_start - 1],  # Last training point = origin\n",
    "            test_start_date=data.index[test_start],\n",
    "            test_end_date=data.index[test_end - 1],\n",
    "            fold_number=i\n",
    "        )\n",
    "        # WHY: origin_date is test_start - 1 because we forecast FROM the last training point\n",
    "        # CONNECTION: This aligns with RollingOrigin evaluation framework\n",
    "        \n",
    "        folds.append(fold)\n",
    "    \n",
    "    print(\"\\nStep 3 Analysis:\")\n",
    "    print(\"===============\")\n",
    "    print(\"✓ Index generation handles the actual data slicing\")\n",
    "    print(\"✓ CVFold creation packages all information together\")\n",
    "    print(\"✓ origin_date calculation aligns with forecasting reality\")\n",
    "    print(\"✓ Complete temporal context enables detailed analysis\")\n",
    "    \n",
    "    return folds\n",
    "\n",
    "print(\"Overall Method Design Rationale:\")\n",
    "print(\"===============================\")\n",
    "print(\"✓ Three-step process: validate, calculate, generate\")\n",
    "print(\"✓ Each step builds on previous parameter validation\")\n",
    "print(\"✓ Clear separation of concerns enables testing and debugging\")\n",
    "print(\"✓ Mathematical rigor ensures temporal consistency\")\n",
    "print(\"✓ Rich metadata supports downstream analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be921b4",
   "metadata": {},
   "source": [
    "## 6. Boundary Calculations: The Mathematical Core\n",
    "\n",
    "The `_calculate_fold_boundaries` method contains the mathematical logic that defines our cross-validation strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_fold_boundaries(self, data_length: int) -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    Calculate fold boundaries for time series cross-validation.\n",
    "    \n",
    "    MATHEMATICAL LOGIC:\n",
    "    Given data of length N, we need to determine (train_start, train_end, test_start, test_end)\n",
    "    for each fold such that:\n",
    "    1. No temporal leakage: train_end + gap ≤ test_start\n",
    "    2. Consistent test windows: test_end - test_start = test_size\n",
    "    3. Proper spacing: test windows are evenly distributed\n",
    "    \n",
    "    Returns: List[(train_start, train_end, test_start, test_end)]\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Calculate available space for cross-validation\n",
    "    available_length = data_length - self.test_size - self.gap\n",
    "    # WHY: We need to reserve space for the last test window plus any gap\n",
    "    # MATH: If data ends at index N-1, last test can start at N-test_size\n",
    "    # CONNECTION: This builds on our initialization validation\n",
    "    \n",
    "    print(\"Boundary Calculation Step 1:\")\n",
    "    print(\"===========================\")\n",
    "    print(f\"Data length: {data_length}\")\n",
    "    print(f\"Test size: {self.test_size}\")  \n",
    "    print(f\"Gap: {self.gap}\")\n",
    "    print(f\"Available for CV: {available_length}\")\n",
    "    print(\"LOGIC: We reserve space at the end for the final test window\")\n",
    "    \n",
    "    # STEP 2: Determine test start positions\n",
    "    if self.n_splits == 1:\n",
    "        # Special case: single split uses all available data\n",
    "        test_starts = [available_length]\n",
    "        # WHY: With one split, we want to use maximum training data\n",
    "        # CONNECTION: Connects to expanding_window philosophy\n",
    "    else:\n",
    "        # Multiple splits: distribute test windows evenly\n",
    "        step_size = available_length // self.n_splits\n",
    "        # WHY: Even distribution gives balanced temporal coverage\n",
    "        # MATH: Integer division ensures we don't exceed available space\n",
    "        \n",
    "        test_starts = [step_size * (i + 1) for i in range(self.n_splits)]\n",
    "        # WHY: Starts at step_size, not 0, to ensure minimum training data\n",
    "        # PATTERN: [step_size, 2*step_size, 3*step_size, ...]\n",
    "        # CONNECTION: This creates the \"rolling\" in rolling origin\n",
    "    \n",
    "    print(\"\\nBoundary Calculation Step 2:\")\n",
    "    print(\"===========================\")\n",
    "    print(f\"Test start positions: {test_starts}\")\n",
    "    print(\"LOGIC: Even spacing ensures representative temporal coverage\")\n",
    "    \n",
    "    # STEP 3: Calculate complete boundaries for each fold\n",
    "    boundaries = []\n",
    "    for i, test_start in enumerate(test_starts):\n",
    "        # Test window: fixed size starting at test_start\n",
    "        test_end = test_start + self.test_size\n",
    "        # WHY: Consistent test window size for fair comparison\n",
    "        # MATH: test_end is exclusive (Python slice convention)\n",
    "        \n",
    "        # Apply gap before test window\n",
    "        train_end = test_start - self.gap\n",
    "        # WHY: Gap prevents data leakage in realistic scenarios\n",
    "        # CONNECTION: Links to our initialization gap parameter\n",
    "        \n",
    "        # Determine training window start\n",
    "        if self.train_size is None:\n",
    "            # Expanding window: use all available data\n",
    "            train_start = 0\n",
    "            # WHY: More training data generally improves performance\n",
    "            # PHILOSOPHY: \"All available information\" approach\n",
    "        else:\n",
    "            # Fixed window: use only recent data\n",
    "            train_start = max(0, train_end - self.train_size)\n",
    "            # WHY: Consistent training data volume across folds\n",
    "            # SAFETY: max(0, ...) prevents negative indices\n",
    "            # TRADE-OFF: Consistency vs maximum information\n",
    "        \n",
    "        boundaries.append((train_start, train_end, test_start, test_end))\n",
    "        \n",
    "        print(f\"\\nFold {i} boundary analysis:\")\n",
    "        print(f\"  Train: [{train_start}:{train_end}] (size: {train_end - train_start})\")\n",
    "        print(f\"  Gap: [{train_end}:{test_start}] (size: {test_start - train_end})\")\n",
    "        print(f\"  Test: [{test_start}:{test_end}] (size: {test_end - test_start})\")\n",
    "    \n",
    "    print(\"\\nBoundary Calculation Step 3:\")\n",
    "    print(\"===========================\")\n",
    "    print(\"✓ Test windows have consistent size\")\n",
    "    print(\"✓ Gap prevents temporal leakage\")\n",
    "    print(\"✓ Training windows follow expanding/fixed strategy\")\n",
    "    print(\"✓ All indices are valid (non-negative, within bounds)\")\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "print(\"Overall Boundary Calculation Rationale:\")\n",
    "print(\"======================================\")\n",
    "print(\"✓ Mathematical rigor ensures temporal consistency\")\n",
    "print(\"✓ Three-step process: available space → test positions → complete boundaries\")\n",
    "print(\"✓ Handles both expanding and fixed window strategies\")\n",
    "print(\"✓ Gap parameter provides realistic forecasting scenarios\")\n",
    "print(\"✓ Boundary validation prevents index errors downstream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff3ca9",
   "metadata": {},
   "source": [
    "## 7. Index Extraction: From Boundaries to Actual Data\n",
    "\n",
    "The `_generate_aligned_indices` method converts our mathematical boundaries into actual data indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_aligned_indices(self, data: pd.DataFrame, \n",
    "                            train_start: int, train_end: int,\n",
    "                            test_start: int, test_end: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate actual indices for train/test splits from boundary positions.\n",
    "    \n",
    "    WHY SEPARATE FROM BOUNDARY CALCULATION:\n",
    "    - Boundaries work with abstract positions\n",
    "    - Indices work with actual data\n",
    "    - Separation enables testing boundary logic independently\n",
    "    - Memory efficiency: create arrays only when needed\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Generate training indices\n",
    "    train_indices = np.arange(train_start, train_end)\n",
    "    # WHY np.arange: Memory efficient, fast integer sequence generation\n",
    "    # CONVENTION: train_end is exclusive (standard Python slicing)\n",
    "    # CONNECTION: Builds directly on boundary calculations\n",
    "    \n",
    "    print(\"Index Extraction Analysis:\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"Train boundaries: [{train_start}:{train_end}]\")\n",
    "    print(f\"Train indices shape: {train_indices.shape}\")\n",
    "    print(f\"Train indices preview: {train_indices[:5]}...{train_indices[-5:]}\")\n",
    "    \n",
    "    # STEP 2: Generate test indices  \n",
    "    test_indices = np.arange(test_start, test_end)\n",
    "    # WHY: Consistent with training index generation\n",
    "    # MEMORY: Small arrays for typical test sizes (1-7 days)\n",
    "    # CONNECTION: test_end from boundary calculation\n",
    "    \n",
    "    print(f\"Test boundaries: [{test_start}:{test_end}]\")\n",
    "    print(f\"Test indices shape: {test_indices.shape}\")\n",
    "    print(f\"Test indices: {test_indices}\")\n",
    "    \n",
    "    # STEP 3: Validation and safety checks\n",
    "    # Ensure no negative indices (shouldn't happen with proper boundaries)\n",
    "    assert train_indices.min() >= 0, f\"Negative training index: {train_indices.min()}\"\n",
    "    assert test_indices.min() >= 0, f\"Negative test index: {test_indices.min()}\"\n",
    "    \n",
    "    # Ensure indices don't exceed data length\n",
    "    assert train_indices.max() < len(data), f\"Training index {train_indices.max()} >= data length {len(data)}\"\n",
    "    assert test_indices.max() < len(data), f\"Test index {test_indices.max()} >= data length {len(data)}\"\n",
    "    \n",
    "    # Ensure temporal order (no training data after test data)\n",
    "    if len(train_indices) > 0 and len(test_indices) > 0:\n",
    "        assert train_indices.max() < test_indices.min(), \"Training data cannot come after test data\"\n",
    "    \n",
    "    print(\"Validation Results:\")\n",
    "    print(\"==================\")\n",
    "    print(\"✓ All indices are non-negative\")\n",
    "    print(\"✓ All indices are within data bounds\")\n",
    "    print(\"✓ Temporal order preserved (train < test)\")\n",
    "    print(\"✓ No data leakage possible\")\n",
    "    \n",
    "    return train_indices, test_indices\n",
    "\n",
    "print(\"Index Extraction Design Rationale:\")\n",
    "print(\"==================================\")\n",
    "print(\"✓ np.ndarray for memory efficiency and fast operations\")\n",
    "print(\"✓ Boundary-to-index separation enables independent testing\")\n",
    "print(\"✓ Comprehensive validation prevents runtime errors\")\n",
    "print(\"✓ Clear temporal ordering enforced at index level\")\n",
    "print(\"✓ Connection: Indices are ready for direct pandas/numpy slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6a586",
   "metadata": {},
   "source": [
    "## 8. Model Training Pipeline: Putting It All Together\n",
    "\n",
    "The `cross_validate_model` method orchestrates the entire cross-validation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995aad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(self, \n",
    "                        model_class,\n",
    "                        data: pd.DataFrame,\n",
    "                        target_col: str,\n",
    "                        feature_cols: List[str],\n",
    "                        model_params: Optional[Dict] = None,\n",
    "                        loss_fn=None) -> CVResults:\n",
    "    \"\"\"\n",
    "    Perform complete cross-validation with per-origin loss tracking.\n",
    "    \n",
    "    ORCHESTRATION PHILOSOPHY:\n",
    "    - This method coordinates but delegates specific tasks\n",
    "    - Each step builds on previous infrastructure\n",
    "    - Comprehensive tracking enables detailed analysis\n",
    "    - Clean separation of model training from CV logic\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Parameter setup and defaults\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "    # WHY: Mutable default argument avoidance (Python best practice)\n",
    "    # CONNECTION: Enables flexible model configuration\n",
    "    \n",
    "    if loss_fn is None:\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "    # WHY: MSE is most common regression loss, good default\n",
    "    # FLEXIBILITY: Can override for custom loss functions\n",
    "    # CONNECTION: torch.nn.MSELoss works with our PyTorch models\n",
    "    \n",
    "    print(\"Cross-Validation Pipeline Step 1:\")\n",
    "    print(\"================================\")\n",
    "    print(\"✓ Default parameters established\")\n",
    "    print(\"✓ Loss function configured\") \n",
    "    print(\"✓ Ready for split generation\")\n",
    "    \n",
    "    # STEP 2: Generate splits using our carefully designed logic\n",
    "    folds = self.get_rolling_origin_aligned_splits(data)\n",
    "    # WHY: This leverages all our previous work (boundaries, indices, validation)\n",
    "    # CONNECTION: Returns List[CVFold] with complete temporal context\n",
    "    # DELEGATION: Uses our proven split generation logic\n",
    "    \n",
    "    print(f\"\\nStep 2: Generated {len(folds)} folds\")\n",
    "    print(\"✓ Each fold has complete temporal context\")\n",
    "    print(\"✓ All validation passed in split generation\")\n",
    "    \n",
    "    # STEP 3: Initialize results tracking\n",
    "    results = CVResults()\n",
    "    # WHY: Uses our structured results container\n",
    "    # CONNECTION: Supports three-tier loss tracking (origin/fold/overall)\n",
    "    # PREPARATION: Ready for statistical testing extraction\n",
    "    \n",
    "    # STEP 4: Train and evaluate each fold\n",
    "    for fold in folds:\n",
    "        print(f\"\\nProcessing Fold {fold.fold_number}:\")\n",
    "        print(f\"  Origin: {fold.origin_date}\")\n",
    "        print(f\"  Train size: {len(fold.train_indices)}\")\n",
    "        print(f\"  Test size: {len(fold.test_indices)}\")\n",
    "        \n",
    "        # Extract data for this fold\n",
    "        X_train = data.iloc[fold.train_indices][feature_cols]\n",
    "        y_train = data.iloc[fold.train_indices][target_col]\n",
    "        X_test = data.iloc[fold.test_indices][feature_cols] \n",
    "        y_test = data.iloc[fold.test_indices][target_col]\n",
    "        # WHY: iloc with our validated indices ensures correct data extraction\n",
    "        # SAFETY: No risk of temporal leakage due to our boundary calculations\n",
    "        # CONNECTION: Uses indices from our CVFold structure\n",
    "        \n",
    "        # Train model in isolation\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        # WHY: Fresh model instance prevents contamination between folds\n",
    "        # ISOLATION: Each fold gets independently trained model\n",
    "        # CONNECTION: Works with any sklearn-compatible interface\n",
    "        \n",
    "        # Generate predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        # WHY: Standard prediction interface\n",
    "        # TEMPORAL: Predictions align with test period\n",
    "        \n",
    "        # Calculate per-step losses for this fold\n",
    "        per_origin_losses = self._calculate_per_origin_losses(\n",
    "            y_test, predictions, fold, loss_fn\n",
    "        )\n",
    "        # WHY: Delegates detailed loss calculation to specialized method\n",
    "        # TRACKING: Maintains per-origin granularity for statistical testing\n",
    "        # CONNECTION: Uses our fold metadata for proper labeling\n",
    "        \n",
    "        # Store results in our structured format\n",
    "        results.per_origin_losses.update(per_origin_losses)\n",
    "        # WHY: Accumulates across all folds for complete picture\n",
    "        # STRUCTURE: Maintains per-origin detail for analysis\n",
    "        \n",
    "        # Calculate and store fold-level loss\n",
    "        fold_loss = np.mean(list(per_origin_losses.values()))\n",
    "        results.per_fold_losses[f\"fold_{fold.fold_number}\"] = fold_loss\n",
    "        # WHY: Fold-level aggregation enables fold comparison\n",
    "        # CONNECTION: Builds intermediate summary from detailed data\n",
    "    \n",
    "    print(\"\\nStep 4 Complete:\")\n",
    "    print(\"================\")\n",
    "    print(\"✓ All folds processed independently\")\n",
    "    print(\"✓ Per-origin losses tracked\")\n",
    "    print(\"✓ Fold-level summaries calculated\")\n",
    "    \n",
    "    # STEP 5: Calculate overall metrics\n",
    "    all_losses = []\n",
    "    for losses_list in results.per_origin_losses.values():\n",
    "        all_losses.extend(losses_list)\n",
    "    # WHY: Flatten all per-origin losses for overall statistics\n",
    "    # CONNECTION: Builds on our per-origin tracking\n",
    "    \n",
    "    results.overall_metrics = {\n",
    "        'mean_loss': np.mean(all_losses),\n",
    "        'std_loss': np.std(all_losses),\n",
    "        'n_origins': len(results.per_origin_losses),\n",
    "        'total_predictions': len(all_losses)\n",
    "    }\n",
    "    # WHY: Standard statistical summaries for model comparison\n",
    "    # RICHNESS: Multiple metrics for different analysis needs\n",
    "    # CONNECTION: Derived from our comprehensive tracking\n",
    "    \n",
    "    print(\"\\nStep 5: Overall Metrics Calculated\")\n",
    "    print(\"=================================\")\n",
    "    print(f\"✓ Mean loss: {results.overall_metrics['mean_loss']:.4f}\")\n",
    "    print(f\"✓ Std loss: {results.overall_metrics['std_loss']:.4f}\")\n",
    "    print(f\"✓ Origins: {results.overall_metrics['n_origins']}\")\n",
    "    print(f\"✓ Predictions: {results.overall_metrics['total_predictions']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Cross-Validation Pipeline Design Rationale:\")\n",
    "print(\"==========================================\")\n",
    "print(\"✓ Orchestration pattern: coordinate but delegate specialized tasks\")\n",
    "print(\"✓ Five-step process: setup → splits → initialize → process → summarize\")\n",
    "print(\"✓ Each step builds on previous infrastructure\")\n",
    "print(\"✓ Comprehensive tracking enables multiple analysis levels\")\n",
    "print(\"✓ Clean model isolation prevents fold contamination\")\n",
    "print(\"✓ Structured results support downstream statistical testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c10ca",
   "metadata": {},
   "source": [
    "## 9. Loss Calculation and Statistical Testing Preparation\n",
    "\n",
    "The final pieces of our implementation focus on detailed loss tracking and preparing data for rigorous statistical comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Calculation: Per-Origin Tracking\n",
    "def _calculate_per_origin_losses(self, y_true: pd.Series, y_pred: np.ndarray, \n",
    "                               fold: CVFold, loss_fn) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Calculate losses for each forecast origin in the test period.\n",
    "    \n",
    "    WHY PER-ORIGIN TRACKING:\n",
    "    - Statistical testing requires matched predictions across models\n",
    "    - Temporal analysis needs origin-specific performance\n",
    "    - Diebold-Mariano test specifically needs per-origin loss differences\n",
    "    \"\"\"\n",
    "    \n",
    "    per_origin_losses = {}\n",
    "    test_dates = y_true.index\n",
    "    \n",
    "    # For each test date, calculate loss and associate with origin\n",
    "    for i, (date, actual) in enumerate(zip(test_dates, y_true.values)):\n",
    "        origin_key = fold.origin_date.strftime('%Y-%m-%d')\n",
    "        # WHY: String keys for JSON serialization and human readability\n",
    "        # CONNECTION: Uses origin_date from our CVFold structure\n",
    "        \n",
    "        if origin_key not in per_origin_losses:\n",
    "            per_origin_losses[origin_key] = []\n",
    "        \n",
    "        # Calculate loss for this prediction\n",
    "        pred_tensor = torch.tensor([y_pred[i]], dtype=torch.float32)\n",
    "        actual_tensor = torch.tensor([actual], dtype=torch.float32)\n",
    "        loss_value = loss_fn(pred_tensor, actual_tensor).item()\n",
    "        # WHY: Tensor conversion enables custom PyTorch loss functions\n",
    "        # CONSISTENCY: .item() extracts scalar value for storage\n",
    "        \n",
    "        per_origin_losses[origin_key].append(loss_value)\n",
    "    \n",
    "    return per_origin_losses\n",
    "\n",
    "# Statistical Testing Preparation\n",
    "def extract_cv_results_for_statistical_testing(cv_results_dict: Dict[str, CVResults]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract and align CV results for statistical testing (e.g., Diebold-Mariano test).\n",
    "    \n",
    "    DIEBOLD-MARIANO TEST REQUIREMENTS:\n",
    "    - Matched predictions: Same forecast origins across models\n",
    "    - Loss differences: Can calculate model_A_loss - model_B_loss\n",
    "    - Temporal alignment: Origins correspond to same time points\n",
    "    \n",
    "    WHY THIS FUNCTION EXISTS:\n",
    "    - Statistical tests need specific data format\n",
    "    - Cross-validation results need alignment across models\n",
    "    - Automation reduces manual error in test setup\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Statistical Testing Preparation:\")\n",
    "    print(\"===============================\")\n",
    "    \n",
    "    # STEP 1: Collect all unique origins across all models\n",
    "    all_origins = set()\n",
    "    for model_name, results in cv_results_dict.items():\n",
    "        all_origins.update(results.per_origin_losses.keys())\n",
    "    # WHY: Ensures we only compare origins that exist in all models\n",
    "    # CONNECTION: Uses our per-origin tracking structure\n",
    "    \n",
    "    print(f\"✓ Found {len(all_origins)} unique forecast origins\")\n",
    "    \n",
    "    # STEP 2: Build aligned DataFrame\n",
    "    aligned_data = []\n",
    "    for origin in sorted(all_origins):  # Sort for consistent ordering\n",
    "        row = {'origin_date': origin}\n",
    "        \n",
    "        # Check if this origin exists in all models\n",
    "        origin_in_all_models = True\n",
    "        for model_name, results in cv_results_dict.items():\n",
    "            if origin not in results.per_origin_losses:\n",
    "                origin_in_all_models = False\n",
    "                break\n",
    "        \n",
    "        if origin_in_all_models:\n",
    "            # Add loss data for each model\n",
    "            for model_name, results in cv_results_dict.items():\n",
    "                losses = results.per_origin_losses[origin]\n",
    "                row[f'{model_name}_loss'] = np.mean(losses)  # Average if multiple predictions per origin\n",
    "                row[f'{model_name}_loss_count'] = len(losses)\n",
    "            aligned_data.append(row)\n",
    "    \n",
    "    print(f\"✓ Aligned {len(aligned_data)} common origins across all models\")\n",
    "    print(\"✓ Ready for Diebold-Mariano test\")\n",
    "    print(\"✓ Each row represents matched predictions from same forecast origin\")\n",
    "    \n",
    "    df = pd.DataFrame(aligned_data)\n",
    "    df['origin_date'] = pd.to_datetime(df['origin_date'])\n",
    "    # WHY: Convert back to datetime for temporal analysis\n",
    "    # CONNECTION: Enables time-based filtering and analysis\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Loss Calculation and Statistical Testing Rationale:\")\n",
    "print(\"=================================================\")\n",
    "print(\"✓ Per-origin tracking enables statistical testing\")\n",
    "print(\"✓ String keys provide human-readable origin identification\")\n",
    "print(\"✓ Tensor operations support custom PyTorch loss functions\")\n",
    "print(\"✓ Alignment function automates test preparation\")\n",
    "print(\"✓ DataFrame output integrates with statistical testing libraries\")\n",
    "print(\"✓ Temporal information preserved for advanced analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa2271",
   "metadata": {},
   "source": [
    "## 10. Practical Demonstration: Seeing It All Work Together\n",
    "\n",
    "Let's create a synthetic example to demonstrate how all these components work together in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic time series data for demonstration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate synthetic time series\n",
    "np.random.seed(42)  # For reproducible results\n",
    "dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "n_points = len(dates)\n",
    "\n",
    "# Create realistic time series patterns\n",
    "trend = np.linspace(100, 150, n_points)  # Long-term trend\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(n_points) / 365.25)  # Annual seasonality\n",
    "noise = np.random.normal(0, 5, n_points)  # Random noise\n",
    "target = trend + seasonal + noise\n",
    "\n",
    "# Create some correlated features\n",
    "feature1 = target + np.random.normal(0, 2, n_points)  # Highly correlated\n",
    "feature2 = 0.5 * target + np.random.normal(0, 10, n_points)  # Moderately correlated\n",
    "feature3 = np.random.normal(50, 15, n_points)  # Uncorrelated\n",
    "\n",
    "# Build DataFrame\n",
    "demo_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'target': target,\n",
    "    'feature1': feature1,\n",
    "    'feature2': feature2,\n",
    "    'feature3': feature3\n",
    "}).set_index('date')\n",
    "\n",
    "print(\"Synthetic Data Overview:\")\n",
    "print(\"=======================\")\n",
    "print(f\"Date range: {demo_data.index.min()} to {demo_data.index.max()}\")\n",
    "print(f\"Data points: {len(demo_data)}\")\n",
    "print(f\"Features: {demo_data.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(demo_data.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(demo_data.tail())\n",
    "\n",
    "# Demonstrate our cross-validator\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CROSS-VALIDATION DEMONSTRATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize our improved cross-validator\n",
    "cv = ImprovedTimeSeriesCrossValidator(\n",
    "    n_splits=5,\n",
    "    train_size=None,  # Expanding window\n",
    "    test_size=30,     # 30-day forecast horizon\n",
    "    gap=1,            # 1-day gap for realistic scenarios\n",
    "    expanding_window=True\n",
    ")\n",
    "\n",
    "print(\"Cross-Validator Configuration:\")\n",
    "print(f\"✓ Number of splits: {cv.n_splits}\")\n",
    "print(f\"✓ Training window: {'Expanding' if cv.train_size is None else f'Fixed ({cv.train_size})'}\")\n",
    "print(f\"✓ Test window size: {cv.test_size} days\")\n",
    "print(f\"✓ Gap between train/test: {cv.gap} days\")\n",
    "\n",
    "# Generate splits\n",
    "folds = cv.get_rolling_origin_aligned_splits(demo_data)\n",
    "\n",
    "print(f\"\\nGenerated {len(folds)} folds:\")\n",
    "print(\"-\" * 40)\n",
    "for fold in folds:\n",
    "    print(f\"Fold {fold.fold_number}:\")\n",
    "    print(f\"  Origin Date: {fold.origin_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Test Period: {fold.test_start_date.strftime('%Y-%m-%d')} to {fold.test_end_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Training Size: {len(fold.train_indices)} days\")\n",
    "    print(f\"  Test Size: {len(fold.test_indices)} days\")\n",
    "    print()\n",
    "\n",
    "# Demonstrate the complete cross-validation process\n",
    "print(\"Running Complete Cross-Validation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Use LinearRegression as our model (sklearn-compatible)\n",
    "results = cv.cross_validate_model(\n",
    "    model_class=LinearRegression,\n",
    "    data=demo_data,\n",
    "    target_col='target',\n",
    "    feature_cols=['feature1', 'feature2', 'feature3'],\n",
    "    model_params={},  # Use defaults for LinearRegression\n",
    "    loss_fn=None  # Use default MSE loss\n",
    ")\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"Overall Metrics:\")\n",
    "for metric, value in results.overall_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(f\"\\nPer-Fold Performance:\")\n",
    "for fold_name, loss in results.per_fold_losses.items():\n",
    "    print(f\"  {fold_name}: {loss:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-Origin Tracking:\")\n",
    "print(f\"  Tracked origins: {len(results.per_origin_losses)}\")\n",
    "print(f\"  First 3 origins: {list(results.per_origin_losses.keys())[:3]}\")\n",
    "\n",
    "# Demonstrate statistical testing preparation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATISTICAL TESTING PREPARATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulate having results from multiple models\n",
    "mock_results = {\n",
    "    'LinearRegression': results,\n",
    "    'MockModel2': results  # In practice, this would be a different model's results\n",
    "}\n",
    "\n",
    "# Extract for statistical testing\n",
    "statistical_df = extract_cv_results_for_statistical_testing(mock_results)\n",
    "\n",
    "print(\"\\nStatistical Testing DataFrame:\")\n",
    "print(statistical_df.head())\n",
    "print(f\"\\nShape: {statistical_df.shape}\")\n",
    "print(f\"Columns: {statistical_df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY INSIGHTS FROM DEMONSTRATION\")\n",
    "print(\"=\"*50)\n",
    "print(\"✓ Complete temporal alignment maintained\")\n",
    "print(\"✓ No data leakage - training always precedes testing\")\n",
    "print(\"✓ Per-origin losses enable statistical testing\")\n",
    "print(\"✓ Fold-level tracking enables performance analysis\")\n",
    "print(\"✓ Overall metrics provide model comparison summary\")\n",
    "print(\"✓ Statistical testing preparation automates complex alignment\")\n",
    "print(\"✓ All design choices contribute to rigorous time series evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ee5fd",
   "metadata": {},
   "source": [
    "## Summary: The Interconnected Web of Design Choices\n",
    "\n",
    "### How Everything Connects\n",
    "\n",
    "Our improved time series cross-validation implementation is a carefully crafted system where each decision builds on previous ones:\n",
    "\n",
    "#### 1. **Theoretical Foundation → Data Structures**\n",
    "- Time series temporal dependencies → CVFold with origin_date tracking\n",
    "- Need for statistical testing → CVResults with per-origin loss storage\n",
    "- Comprehensive analysis needs → Three-tier result hierarchy\n",
    "\n",
    "#### 2. **Data Structures → Class Architecture**\n",
    "- Type safety requirements → Comprehensive type hints and validation\n",
    "- Temporal context needs → Explicit date handling in initialization\n",
    "- Flexibility demands → Optional parameters with sensible defaults\n",
    "\n",
    "#### 3. **Class Architecture → Split Generation**\n",
    "- Parameter validation → Boundary calculation safety checks\n",
    "- Temporal order requirements → Mathematical boundary logic\n",
    "- Index efficiency needs → Separate boundary/index generation\n",
    "\n",
    "#### 4. **Split Generation → Loss Tracking**\n",
    "- Per-origin alignment → Origin-based loss dictionary keys\n",
    "- Statistical testing needs → Matched prediction tracking\n",
    "- Temporal analysis → Date-string keys for human readability\n",
    "\n",
    "#### 5. **Loss Tracking → Statistical Testing**\n",
    "- Diebold-Mariano requirements → Per-origin loss differences\n",
    "- Model comparison needs → Aligned DataFrame output\n",
    "- Automation goals → Extract function for complex alignment\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Every line serves multiple purposes**: Our origin_date calculation aligns CV splits with evaluation framework AND enables statistical testing AND provides temporal context for analysis.\n",
    "\n",
    "2. **Separation of concerns enables testing**: By separating boundary calculation from index generation, we can test mathematical logic independently of data handling.\n",
    "\n",
    "3. **Type safety prevents silent failures**: Comprehensive type hints and validation catch errors early rather than producing misleading results.\n",
    "\n",
    "4. **Rich metadata enables deep analysis**: Storing complete temporal context in CVFold enables debugging, visualization, and advanced analysis patterns.\n",
    "\n",
    "5. **Structured results support multiple use cases**: The three-tier CVResults structure serves immediate model comparison, detailed fold analysis, and rigorous statistical testing.\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Traditional cross-validation approaches for time series often:\n",
    "- Lose temporal context\n",
    "- Enable data leakage\n",
    "- Provide insufficient information for statistical testing\n",
    "- Lack rigorous validation\n",
    "\n",
    "Our implementation addresses each of these issues through:\n",
    "- **Explicit temporal tracking** in every data structure\n",
    "- **Mathematical rigor** in boundary calculations\n",
    "- **Comprehensive loss tracking** for statistical testing\n",
    "- **Extensive validation** at every step\n",
    "\n",
    "This creates a foundation for **rigorous, reproducible, and statistically sound** time series model evaluation.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "With this implementation, you can:\n",
    "1. **Confidently compare models** using Diebold-Mariano tests\n",
    "2. **Analyze temporal performance patterns** using per-origin data\n",
    "3. **Debug cross-validation issues** using fold-level tracking\n",
    "4. **Extend the framework** for custom loss functions and model types\n",
    "\n",
    "The deep interconnections between components mean that modifications should be made carefully, understanding how each change propagates through the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_VU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
